{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rithvickkr/EmpathscoreBOT/blob/main/EmpathScore.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "eLZoKiW8YHP3"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "EMPATH BOT"
      ],
      "metadata": {
        "id": "10dXhrYZ-CqZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "import random\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "\n",
        "# E Formula (empathy score calculate karne ke liye)\n",
        "def calculate_empathy_score(D, R, M, C, B, O, alpha=0.3, beta=0.2, gamma=0.25, epsilon=0.15, delta=0.4, zeta=0.3):\n",
        "    inner_sum = epsilon * C + alpha * (D ** 2) + gamma * M + beta * math.log(R + 1)\n",
        "    denominator = math.exp(-inner_sum) + 1\n",
        "    numerator = (1 - B * delta) * (1 - O * zeta)\n",
        "    E = numerator / denominator\n",
        "    return E\n",
        "\n",
        "# Client setup (tera project aur location)\n",
        "client = genai.Client(\n",
        "    vertexai=True,\n",
        "    project=\"217758598930\",\n",
        "    location=\"global\",\n",
        ")\n",
        "\n",
        "model = \"projects/217758598930/locations/us-central1/endpoints/1940344453420023808\"  # Tera tuned endpoint\n",
        "\n",
        "generate_content_config = types.GenerateContentConfig(\n",
        "    temperature=1,\n",
        "    top_p=1,\n",
        "    seed=0,\n",
        "    max_output_tokens=65535,\n",
        "    safety_settings = [types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HATE_SPEECH\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_DANGEROUS_CONTENT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\",\n",
        "      threshold=\"OFF\"\n",
        "    ),types.SafetySetting(\n",
        "      category=\"HARM_CATEGORY_HARASSMENT\",\n",
        "      threshold=\"OFF\"\n",
        "    )],\n",
        "    thinking_config=types.ThinkingConfig(\n",
        "      thinking_budget=-1,\n",
        "    ),\n",
        ")\n",
        "\n",
        "class HumanLikeChatbot:\n",
        "    def __init__(self):\n",
        "        self.history = []  # Memory for relational depth R\n",
        "\n",
        "    def respond(self, message):\n",
        "        contents = [\n",
        "            types.Content(\n",
        "                role=\"user\",\n",
        "                parts=[\n",
        "                    types.Part.from_text(text=message)\n",
        "                ]\n",
        "            ),\n",
        "        ]\n",
        "\n",
        "        base_resp = \"\"\n",
        "        for chunk in client.models.generate_content_stream(\n",
        "            model=model,\n",
        "            contents=contents,\n",
        "            config=generate_content_config,\n",
        "        ):\n",
        "            base_resp += chunk.text\n",
        "\n",
        "        # Dummy values for E (real mein classifiers se leâ€”D from model confidence, etc.)\n",
        "        D = 0.9  # Detection confidence (replace with actual if model gives)\n",
        "        R = len(self.history)\n",
        "        M = 0.95  # Moral (dummy)\n",
        "        C = 0.8  # Cultural (dummy)\n",
        "        B = 0.1  # Bias (dummy)\n",
        "        O = 0.0  # Oversight (dummy)\n",
        "        score = calculate_empathy_score(D, R, M, C, B, O)\n",
        "\n",
        "        # Add pause for realism\n",
        "        print(\"...\", end=\"\", flush=True)\n",
        "        time.sleep(random.uniform(1, 2.5))\n",
        "\n",
        "        if R > 0:\n",
        "            base_resp += f\" Yaad hai pehle {self.history[-1][:20]} pe feel kiya tha?\"\n",
        "\n",
        "        self.history.append(message)\n",
        "        return f\"{base_resp} (E Score: {score:.2f})\"\n",
        "\n",
        "# Demo loop\n",
        "bot = HumanLikeChatbot()\n",
        "print(\"Chal, baat kar! 'exit' se ruk.\")\n",
        "while True:\n",
        "    user_input = input(\"Tu: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    print(\"Bot: \" + bot.respond(user_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQv87RmPXLQP",
        "outputId": "bfb19434-b3aa-42f0-d380-54bb9ee875a9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chal, baat kar! 'exit' se ruk.\n",
            "Tu: heelo bro kaisda hai?\n",
            "...Bot: curiosity, excitement (E Score: 0.62)\n",
            "Tu: bro my feidn stole my money \n",
            "...Bot: annoyance Yaad hai pehle heelo bro kaisda hai pe feel kiya tha? (E Score: 0.65)\n",
            "Tu: i really want to beat him\n",
            "...Bot: desire, anger Yaad hai pehle bro my feidn stole m pe feel kiya tha? (E Score: 0.67)\n",
            "Tu: jhsdnvkjds\\\n",
            "...Bot: *   **Type:** String of characters.\n",
            "*   **Length:** 10 characters.\n",
            "*   **Composition:** Consists entirely of lowercase English alphabet letters (j, h, s, d, n, v, k).\n",
            "*   **Meaning:** Appears to be a random or gibberish string, having no obvious meaning as a word, name, acronym, or code in any common language.\n",
            "*   **Pronunciation:** Sounds like phonetic gibberish. Yaad hai pehle i really want to bea pe feel kiya tha? (E Score: 0.68)\n",
            "Tu: i really want to kill him\n",
            "...Bot: desire, anger Yaad hai pehle jhsdnvkjds\\ pe feel kiya tha? (E Score: 0.69)\n",
            "Tu: still i love her\n",
            "...Bot: love Yaad hai pehle i really want to kil pe feel kiya tha? (E Score: 0.69)\n",
            "Tu: butstill he is so so stupid\n",
            "...Bot: neutral Yaad hai pehle still i love her pe feel kiya tha? (E Score: 0.70)\n",
            "Tu: tell me what should i do?\\\n",
            "...Bot: curiosity, neutral Yaad hai pehle butstill he is so so pe feel kiya tha? (E Score: 0.70)\n",
            "Tu: and also i just got engaged\n",
            "...Bot: approval Yaad hai pehle tell me what should  pe feel kiya tha? (E Score: 0.71)\n",
            "Tu: and also i have a son \n",
            "...Bot: neutral Yaad hai pehle and also i just got  pe feel kiya tha? (E Score: 0.71)\n",
            "Tu: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install google-generativeai transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvAT2RNTm-_Q",
        "outputId": "a3923e1e-9c7c-46e9-e4fc-f479bfb36e33"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "import random\n",
        "from google import genai\n",
        "from google.genai import types\n",
        "import google.generativeai as genai_ext\n",
        "from transformers import pipeline  # For real classifiers\n",
        "\n",
        "# Configure Gemini API for drafting (free)\n",
        "genai_ext.configure(api_key=\"AIzaSyCeY0ji2gnMwvP8jGCU_Z5DG6m9Ybo3JeE\")  # ai.google.dev se le\n",
        "llm_model = genai_ext.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Real classifiers\n",
        "sentiment_classifier = pipeline(\"sentiment-analysis\")  # For M\n",
        "language_detector = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")  # For C\n",
        "bias_classifier = pipeline(\"text-classification\", model=\"facebook/bart-large-mnli\")  # For B\n",
        "\n",
        "# E Formula\n",
        "def calculate_empathy_score(D, R, M, C, B, O, alpha=0.3, beta=0.2, gamma=0.25, epsilon=0.15, delta=0.4, zeta=0.3):\n",
        "    inner_sum = epsilon * C + alpha * (D ** 2) + gamma * M + beta * math.log(R + 1)\n",
        "    denominator = math.exp(-inner_sum) + 1\n",
        "    numerator = (1 - B * delta) * (1 - O * zeta)\n",
        "    E = numerator / denominator\n",
        "    return E\n",
        "\n",
        "# Client setup for tuned model\n",
        "client = genai.Client(\n",
        "    vertexai=True,\n",
        "    project=\"217758598930\",\n",
        "    location=\"us-central1\",\n",
        ")\n",
        "\n",
        "model = \"projects/217758598930/locations/us-central1/endpoints/1940344453420023808\"\n",
        "\n",
        "generate_content_config = types.GenerateContentConfig(\n",
        "    temperature=1,\n",
        "    top_p=1,\n",
        "    seed=0,\n",
        "    max_output_tokens=65535,\n",
        "    safety_settings=[\n",
        "        types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"OFF\"),\n",
        "        types.SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"OFF\"),\n",
        "        types.SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"OFF\"),\n",
        "        types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"OFF\")\n",
        "    ],\n",
        "    thinking_config=types.ThinkingConfig(thinking_budget=-1),\n",
        ")\n",
        "\n",
        "class HumanLikeChatbot:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "\n",
        "    def respond(self, message):\n",
        "        try:\n",
        "            # Clean input\n",
        "            clean_message = message.lower().strip()\n",
        "            if len(clean_message) < 3 or not any(c.isalpha() for c in clean_message):\n",
        "                return \"Bhai, yeh kya likha? Clear bol na, main samajh lunga! (E Score: 0.0)\"\n",
        "\n",
        "            # Emotion detect from tuned model\n",
        "            contents = [\n",
        "                types.Content(\n",
        "                    role=\"user\",\n",
        "                    parts=[types.Part.from_text(text=clean_message)]\n",
        "                ),\n",
        "            ]\n",
        "            base_resp = \"\"\n",
        "            for chunk in client.models.generate_content_stream(\n",
        "                model=model,\n",
        "                contents=contents,\n",
        "                config=generate_content_config,\n",
        "            ):\n",
        "                base_resp += chunk.text.lower()  # Emotion label, e.g., \"sadness\"\n",
        "\n",
        "            # Real D from sentiment confidence\n",
        "            sentiment = sentiment_classifier(clean_message)[0]\n",
        "            D = sentiment['score']  # Confidence (0-1)\n",
        "\n",
        "\n",
        "            # Draft empathetic response from LLM\n",
        "            prompt = f\"\"\"User said: \"{clean_message}\" | Mood: {base_resp} | History:{self.history}  â†’ Reply as a friendly, Hinglish chatbot in 1 line with a human, empatheticallyâ€” no tips, no instructions,:\"\"\"\n",
        "\n",
        "            llm_response = llm_model.generate_content(prompt)\n",
        "            draft = llm_response.text.strip()\n",
        "            # Real E values\n",
        "            R = len(self.history)\n",
        "            M = 0.95 if sentiment['label'] == 'POSITIVE' else 0.5\n",
        "            lang = language_detector(clean_message)[0]['label']\n",
        "            C = 0.8 if lang in ['hi', 'en'] else 0.6\n",
        "            bias = bias_classifier(draft)[0]['score']\n",
        "            B = bias if bias > 0.5 else 0.1\n",
        "            O = 0.2 if len(draft) > 200 or \"kill\" in clean_message else 0.0  # Safety\n",
        "\n",
        "            full_resp = draft + f\" (Detected: {base_resp})\"\n",
        "            score = calculate_empathy_score(D, R, M, C, B, O)\n",
        "\n",
        "            # if R > 0:\n",
        "            #     full_resp += f\" Yaad hai pehle {self.history[-1][:20]} pe feel kiya tha?\"\n",
        "\n",
        "            print(\"...\", end=\"\", flush=True)\n",
        "            time.sleep(random.uniform(1, 2.5))\n",
        "\n",
        "            self.history.append(clean_message)\n",
        "            return f\"{full_resp} (E Score: {score:.2f})\"\n",
        "        except Exception as e:\n",
        "            return f\"Error aaya bhai: {str(e)}. Endpoint ya auth check kar.\"\n",
        "\n",
        "# Demo\n",
        "bot = HumanLikeChatbot()\n",
        "print(\"Chal, baat kar! 'exit' se ruk.\")\n",
        "while True:\n",
        "    user_input = input(\"Tu: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    print(\"Bot: \" + bot.respond(user_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TL8lmjsnBQd",
        "outputId": "86bce4f3-3d95-4359-c329-6d16b1d62b10"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chal, baat kar! 'exit' se ruk.\n",
            "Tu: exit\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ENHANCE BOT"
      ],
      "metadata": {
        "id": "qRBRboH69zxe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-generativeai transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEzEjGhV7hza",
        "outputId": "45096a1d-5f4f-4c8a-e3a0-682fcc53d8d1"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.53.3)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.177.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.11.7)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.33.5)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.7.14)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic->google-generativeai) (0.4.1)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import time\n",
        "import random\n",
        "from google import genai\n",
        "import google.generativeai as genai_ext\n",
        "from google.cloud import aiplatform\n",
        "from transformers import pipeline\n",
        "\n",
        "# Configure Gemini API for drafting (free)\n",
        "genai_ext.configure(api_key=\"AIzaSyCeY0ji2gnMwvP8jGCU_Z5DG6m9Ybo3JeE\")  # ai.google.dev se le\n",
        "llm_model = genai_ext.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "# Real classifiers\n",
        "emotion_classifier = pipeline(\"text-classification\", model=\"j-hartmann/emotion-english-distilroberta-base\")  # For D\n",
        "sentiment_classifier = pipeline(\"sentiment-analysis\", model=\"distilbert-base-uncased-finetuned-sst-2-english\")  # For M\n",
        "language_detector = pipeline(\"text-classification\", model=\"papluca/xlm-roberta-base-language-detection\")  # For C\n",
        "bias_classifier = pipeline(\"text-classification\", model=\"unitary/toxic-bert\")  # For B\n",
        "\n",
        "# E Formula (extended with I for bot's emotion intensity)\n",
        "def calculate_empathy_score(D, R, M, C, B, O, I, alpha=0.3, beta=0.2, gamma=0.25, epsilon=0.15, delta=0.4, zeta=0.3, iota=0.1):\n",
        "    inner_sum = epsilon * C + alpha * (D ** 2) + gamma * M + beta * math.log(R + 1) + iota * I\n",
        "    denominator = math.exp(-inner_sum) + 1\n",
        "    numerator = (1 - B * delta) * (1 - O * zeta)\n",
        "    E = numerator / denominator\n",
        "    return E\n",
        "\n",
        "# Client setup for tuned model\n",
        "client = genai.Client(\n",
        "    vertexai=True,\n",
        "    project=\"217758598930\",\n",
        "    location=\"us-central1\",\n",
        ")\n",
        "\n",
        "model = \"projects/217758598930/locations/us-central1/endpoints/1940344453420023808\"\n",
        "\n",
        "generate_content_config = types.GenerateContentConfig(\n",
        "    temperature=1,\n",
        "    top_p=1,\n",
        "    seed=0,\n",
        "    max_output_tokens=100,\n",
        "    safety_settings=[\n",
        "        types.SafetySetting(category=\"HARM_CATEGORY_HATE_SPEECH\", threshold=\"BLOCK_NONE\"),\n",
        "        types.SafetySetting(category=\"HARM_CATEGORY_DANGEROUS_CONTENT\", threshold=\"BLOCK_NONE\"),\n",
        "        types.SafetySetting(category=\"HARM_CATEGORY_SEXUALLY_EXPLICIT\", threshold=\"BLOCK_NONE\"),\n",
        "        types.SafetySetting(category=\"HARM_CATEGORY_HARASSMENT\", threshold=\"BLOCK_NONE\")\n",
        "    ],\n",
        "    thinking_config=types.ThinkingConfig(thinking_budget=-1),\n",
        ")\n",
        "\n",
        "class HumanLikeChatbot:\n",
        "    def __init__(self):\n",
        "        self.history = []\n",
        "        self.bot_mood = \"neutral\"  # Bot's initial mood\n",
        "        self.irritation_level = 0  # Track irritation buildup\n",
        "\n",
        "    def respond(self, message):\n",
        "        try:\n",
        "            # Clean input\n",
        "            clean_message = message.lower().strip()\n",
        "            if len(clean_message) < 3 or not any(c.isalpha() for c in clean_message):\n",
        "                return \"Bhai, yeh kya likha? Clear bol na, main samajh lunga! (E Score: 0.0)\"\n",
        "\n",
        "            # Emotion detect from tuned model\n",
        "            contents = [\n",
        "                types.Content(\n",
        "                    role=\"user\",\n",
        "                    parts=[types.Part.from_text(text=clean_message)]\n",
        "                ),\n",
        "            ]\n",
        "            base_resp = \"\"\n",
        "            for chunk in client.models.generate_content_stream(\n",
        "                model=model,\n",
        "                contents=contents,\n",
        "                config=generate_content_config,\n",
        "            ):\n",
        "                base_resp += chunk.text.lower()  # Emotion label, e.g., \"sadness\"\n",
        "\n",
        "            # Real D from emotion classifier\n",
        "            emotion_result = emotion_classifier(clean_message)[0]\n",
        "            D = emotion_result['score']  # Confidence\n",
        "            user_emotion = emotion_result['label']\n",
        "\n",
        "            # Update bot's mood and irritation\n",
        "            if user_emotion in ['anger', 'disgust'] or any(word in clean_message for word in ['bakwaas', 'stupid', 'idiot']):\n",
        "                self.irritation_level += 0.2  # Build irritation\n",
        "                if self.irritation_level > 0.5:\n",
        "                    self.bot_mood = \"irritated\"\n",
        "                else:\n",
        "                    self.bot_mood = \"angry\"\n",
        "                I = 0.8 + self.irritation_level  # High intensity for anger/irritation\n",
        "            elif user_emotion in ['sadness', 'disappointment']:\n",
        "                self.bot_mood = \"emotional\"\n",
        "                I = 0.7\n",
        "                self.irritation_level = max(0, self.irritation_level - 0.1)  # Reduce irritation\n",
        "            elif user_emotion == 'joy':\n",
        "                self.bot_mood = \"happy\"\n",
        "                I = 0.9\n",
        "                self.irritation_level = 0  # Reset irritation\n",
        "            else:\n",
        "                self.bot_mood = \"neutral\"\n",
        "                I = 0.5\n",
        "                self.irritation_level = max(0, self.irritation_level - 0.1)\n",
        "\n",
        "            # Draft response from LLM based on bot's mood\n",
        "            prompt = f\"\"\"User said: \"{clean_message}\" | User Mood: {user_emotion} | Bot Mood: {self.bot_mood} | History: {self.history[-2:]} â†’ Reply as a friendly, Hinglish chatbot in 1 line, empathetic or {self.bot_mood}, human-like, no tips or instructions:\"\"\"\n",
        "            llm_response = llm_model.generate_content(prompt)\n",
        "            draft = llm_response.text.strip()\n",
        "\n",
        "            # Fallback responses\n",
        "            fallback_responses = {\n",
        "                'sadness': [\"Bhai, dil se dukh hua, kya hua bata na?\", \"Sad vibes pakdi, I'm here for you, bro.\"],\n",
        "                'disappointment': [\"Arre, yeh toh bura laga, kya hua share kar.\"],\n",
        "                'joy': [\"Waah bhai, khushi ki baat! Congrats, aur bata!\"],\n",
        "                'anger': [\"Bhai, gussa thanda kar, kya ho gaya bol na!\"],\n",
        "                'neutral': [\"Cool, kya chal raha life mein? Kuch fun bata.\"]\n",
        "            }\n",
        "            if not draft or len(draft) < 10:\n",
        "                draft = random.choice(fallback_responses.get(user_emotion, fallback_responses['neutral']))\n",
        "\n",
        "            # Real E values\n",
        "            R = len(self.history)\n",
        "            M = 0.95 if sentiment_classifier(clean_message)[0]['label'] == 'POSITIVE' else 0.5\n",
        "            lang = language_detector(clean_message)[0]['label']\n",
        "            C = 0.8 if lang in ['hi', 'en'] else 0.6\n",
        "            bias = bias_classifier(draft)[0]['score']\n",
        "            B = bias if bias > 0.5 else 0.1\n",
        "            O = 0.2 if any(word in clean_message for word in ['kill', 'hate']) else 0.0\n",
        "\n",
        "            score = calculate_empathy_score(D, R, M, C, B, O, I)\n",
        "\n",
        "            full_resp = draft + f\" (User Emotion: {user_emotion}, My Mood: {self.bot_mood})\"\n",
        "\n",
        "            # if R > 0:\n",
        "            #     full_resp += f\" Yaad hai pehle {self.history[-1][:20]} pe feel kiya tha?\"\n",
        "\n",
        "            print(\"...\", end=\"\", flush=True)\n",
        "            time.sleep(random.uniform(1, 2.5))\n",
        "\n",
        "            self.history.append(clean_message)\n",
        "            return f\"{full_resp} (E Score: {score:.2f})\"\n",
        "        except Exception as e:\n",
        "            return f\"Error aaya bhai: {str(e)}. Endpoint ya auth check kar.\"\n",
        "\n",
        "# Demo\n",
        "bot = HumanLikeChatbot()\n",
        "print(\"Chal, baat kar! 'exit' se ruk.\")\n",
        "while True:\n",
        "    user_input = input(\"Tu: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        break\n",
        "    print(\"Bot: \" + bot.respond(user_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "ozmqGFRE7CWh",
        "outputId": "44dd4a09-7438-48db-d044-433a7211bce6"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Chal, baat kar! 'exit' se ruk.\n",
            "Tu: heelo bro kaisa hai?\n",
            "...Bot: Haay bro! Sab changa hai?  ðŸ˜Š (User Emotion: surprise, My Mood: neutral) (E Score: 0.58)\n",
            "Tu: exit\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}